"""Converts pre-processed Clickbait17 data into a format suitable for a headline classifier.

The script reads CSV files generated by 'clickbait17_prepare.py' and
transforms them into a simplified format with two columns: 'headline' and 'clickbait'.
The 'headline' is a combination of the 'post' and 'headline' fields from the original
dataset, and the 'clickbait' column is a binarized version of the original
'clickbait_score'.
"""
import os
import pandas as pd
import logging
from data.clickbait17.clickbait17_utils import get_dataset_folder, combined_headline_series
from config import DATASETS_CONFIG, HEADLINE_CONTENT_CONFIG, GENERAL_CONFIG

logger = logging.getLogger(__name__)

def _binarise(score: float, threshold: float = GENERAL_CONFIG["clickbait_threshold"]) -> int:
    """Converts a continuous clickbait score to a binary label.

    Args:
        score: The clickbait score, a float between 0 and 1.
        threshold: The threshold to use for binarization. Scores greater than
            or equal to this value will be labeled as 1 (clickbait), and
            scores below this value will be labeled as 0 (not clickbait).

    Returns:
        An integer (0 or 1) representing the binary clickbait label.
    """
    return 1 if score >= threshold else 0

def prepare_headline_classifier_dataset_from_csv(input_csv_dir: str = None, output_path: str = None):
    """Creates datasets for a headline classifier from pre-existing Clickbait17 CSV files.

    This function reads the train, validation, and test CSV files generated by the
    main data preparation script and transforms them into a simple 'headline' and
    'clickbait' format.

    Args:
        input_csv_dir: The directory where the input CSV files are located. If
            not provided, a default path is constructed based on the tokenizer
            name in the configuration.
        output_path: The directory where the output CSV files will be saved.
            If not provided, a default path of 'data/headline_classifier_dataset'
            is used.
    """
    logger.info("\n--- Preparing datasets for HeadlineClassifier from Clickbait17 CSVs ---")

    # Set default input directory if not provided, based on the tokenizer configuration
    if input_csv_dir is None:
        # Assume a default location based on the original prepare script's output
        default_tokenizer = HEADLINE_CONTENT_CONFIG["tokenizer_name"]
        input_csv_dir = get_dataset_folder(default_tokenizer)
        logger.info(f"Input CSV directory not provided, defaulting to: {input_csv_dir}")

    # Set default output path if not provided
    if output_path is None:
        output_path = os.path.join("data", "headline_classifier_dataset")

    os.makedirs(output_path, exist_ok=True)
    logger.info(f"Output directory set to: {output_path}")

    # The suffixes for train, validation, and test dataset files
    subsets = {
        "train": DATASETS_CONFIG["train_suffix"],
        "validation": DATASETS_CONFIG["validation_suffix"],
        "test": DATASETS_CONFIG["test_suffix"]
    }

    # Process each subset (train, validation, test)
    for subset_key, subset_name in subsets.items():
        output_filename = os.path.join(output_path, f"clickbait17_headline_{subset_key}.csv")

        # Skip if the output file already exists to save time
        if os.path.exists(output_filename):
            logger.info(f"Dataset for '{subset_key}' already exists at {output_filename}. Skipping.")
            continue

        # Path to the input CSV file for the current subset
        input_csv_filename = os.path.join(input_csv_dir, f"{DATASETS_CONFIG['dataset_headline_content_name']}_{subset_name}.csv")

        # Check if the required input file exists before proceeding.
        if not os.path.exists(input_csv_filename):
            logger.error(f"Input CSV not found: {input_csv_filename}. Please ensure this file exists. You may need to run the main 'clickbait17_prepare.py' script first.")
            continue

        logger.info(f"Creating dataset for '{subset_key}' from {input_csv_filename}...")

        # Load the original Clickbait17 data from the CSV file to dataframe
        try:
            original_df = pd.read_csv(input_csv_filename)
            if original_df.empty:
                logger.warning(f"The input CSV {input_csv_filename} is empty. Skipping.")
                continue
        except Exception as e:
            logger.error(f"Failed to read CSV file {input_csv_filename}: {e}")
            continue

        # Create the new DataFrame with the required format
        logger.info(f"Transforming data for '{subset_key}'...")
        headline_classifier_df = pd.DataFrame()
        # Combine 'post' and 'headline' from the original data to create the new 'headline'.
        headline_classifier_df['headline'] = combined_headline_series(original_df)
        # Binarize 'clickbait_score' into 'clickbait'
        headline_classifier_df['clickbait'] = original_df['clickbait_score'].apply(_binarise)

        # Save the DataFrame to a CSV file
        headline_classifier_df.to_csv(output_filename, index=False)
        logger.info(f"Successfully saved '{subset_key}' dataset to {output_filename}")

    logger.info("\n--- Dataset preparation for HeadlineClassifier complete. ---")

if __name__ == "__main__":
    import logging_config
    prepare_headline_classifier_dataset_from_csv()