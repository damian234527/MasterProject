"""Converts pre-processed Clickbait17 data for a headline-only classifier.

This script reads the general-purpose CSV files generated by other data
preparation scripts and transforms them into a simplified, two-column format
with 'headline' and 'clickbait' columns. The 'headline' is a combination of
the 'post' and 'headline' fields from the original data, and the 'clickbait'
column is a binarized version of the original 'clickbait_score'. This format
is ideal for training a simple, fast headline-only classifier.
"""
import os
import pandas as pd
import logging
from data.clickbait17.clickbait17_utils import get_dataset_folder, combined_headline_series
from config import DATASETS_CONFIG, HEADLINE_CONTENT_CONFIG, GENERAL_CONFIG

logger = logging.getLogger(__name__)


def _binarise(score: float, threshold: float = GENERAL_CONFIG["clickbait_threshold"]) -> int:
    """Converts a continuous clickbait score to a binary label.

    Args:
        score (float): The clickbait score, typically between 0 and 1.
        threshold (float): The cutoff for binarization. Scores greater than or
            equal to this value become 1 (clickbait), and scores below
            become 0 (not clickbait).

    Returns:
        An integer (0 or 1) representing the binary clickbait label.
    """
    return 1 if score >= threshold else 0


def prepare_headline_classifier_dataset_from_csv(input_csv_dir: str = None, output_path: str = None):
    """Creates datasets for a headline classifier from existing Clickbait17 CSVs.

    This function reads the train, validation, and test CSV files from a specified
    directory and transforms them into a simple 'headline' and 'clickbait' format,
    saving them to a new location.

    Args:
        input_csv_dir (str, optional): The directory where the source Clickbait17
            CSV files are located. If not provided, a default path is constructed.
        output_path (str, optional): The directory where the new, simplified
            CSV files will be saved. Defaults to 'data/headline_classifier_dataset'.
    """
    logger.info("\n--- Preparing datasets for HeadlineClassifier from Clickbait17 CSVs ---")

    # Set default input and output directories if not provided.
    if input_csv_dir is None:
        default_tokenizer = HEADLINE_CONTENT_CONFIG["tokenizer_name"]
        input_csv_dir = get_dataset_folder(default_tokenizer)
        logger.info(f"Input CSV directory not provided, defaulting to: {input_csv_dir}")
    if output_path is None:
        output_path = os.path.join("data", "headline_classifier_dataset")

    os.makedirs(output_path, exist_ok=True)
    logger.info(f"Output directory set to: {output_path}")

    subsets = {
        "train": DATASETS_CONFIG["train_suffix"],
        "validation": DATASETS_CONFIG["validation_suffix"],
        "test": DATASETS_CONFIG["test_suffix"]
    }

    # Process each subset (train, validation, test).
    for subset_key, subset_name in subsets.items():
        output_filename = os.path.join(output_path, f"clickbait17_headline_{subset_key}.csv")

        # Skip if the output file already exists to avoid reprocessing.
        if os.path.exists(output_filename):
            logger.info(f"Dataset for '{subset_key}' already exists at {output_filename}. Skipping.")
            continue

        input_csv_filename = os.path.join(input_csv_dir,
                                          f"{DATASETS_CONFIG['dataset_headline_content_name']}_{subset_name}.csv")

        if not os.path.exists(input_csv_filename):
            logger.error(f"Input CSV not found: {input_csv_filename}. Please run the main preparation script first.")
            continue

        logger.info(f"Creating dataset for '{subset_key}' from {input_csv_filename}...")

        try:
            original_df = pd.read_csv(input_csv_filename)
            if original_df.empty:
                logger.warning(f"The input CSV {input_csv_filename} is empty. Skipping.")
                continue
        except Exception as e:
            logger.error(f"Failed to read CSV file {input_csv_filename}: {e}")
            continue

        # Create the new DataFrame in the desired format.
        logger.info(f"Transforming data for '{subset_key}'...")
        headline_classifier_df = pd.DataFrame()
        # Combine 'post' and 'headline' from the source data into the new 'headline'.
        headline_classifier_df['headline'] = combined_headline_series(original_df)
        # Binarize the 'clickbait_score' to create the new 'clickbait' label.
        headline_classifier_df['clickbait'] = original_df['clickbait_score'].apply(_binarise)

        # Save the transformed DataFrame to a new CSV file.
        headline_classifier_df.to_csv(output_filename, index=False)
        logger.info(f"Successfully saved '{subset_key}' dataset to {output_filename}")

    logger.info("\n--- Dataset preparation for HeadlineClassifier complete. ---")


if __name__ == "__main__":
    import logging_config
    # Run the preparation process with default paths.
    prepare_headline_classifier_dataset_from_csv()